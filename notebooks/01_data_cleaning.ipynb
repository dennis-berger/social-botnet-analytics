{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9242be5",
   "metadata": {},
   "source": [
    "# 01_data_cleaning\n",
    "\n",
    "**Purpose:**  \n",
    "1. Load the raw MGTAB graph via our `MGTAB` loader  \n",
    "2. Profile key elements (features, labels, edges) for missing values, duplicates, self‐loops  \n",
    "3. Perform simple cleaning operations (e.g. remove self‐loops, dedupe edges)  \n",
    "4. Save cleaned artifacts for downstream use  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97da880b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# ensure repo root on path\n",
    "os.chdir(os.path.abspath('..'))\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from src.data.mgtab_dataset import MGTAB\n",
    "from torch_geometric.utils import to_networkx, remove_self_loops, coalesce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ed57f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: config/config.yaml\n",
      "Data(x=[10199, 788], edge_index=[2, 1700108], edge_type=[1700108], edge_weight=[1700108], y_stance=[10199], y_bot=[10199], train_mask=[10199], val_mask=[10199], test_mask=[10199])\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "import yaml\n",
    "cfg_path = os.path.join('config', 'config.yaml')\n",
    "print(\"Loading config from:\", cfg_path)\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# instantiate dataset\n",
    "from src.data.mgtab_dataset import MGTAB\n",
    "dataset = MGTAB(root=cfg['mgtab_root'])\n",
    "data = dataset[0]\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afeb59",
   "metadata": {},
   "source": [
    "## 4.1 Feature Matrix Inspection\n",
    "- Shape  \n",
    "- Missing or NaN values per feature  \n",
    "- Feature distribution summary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab53140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (10199, 788)\n",
      "Num features with NaNs: 0\n",
      "Top 5 features by NaN count: [  0 520 521 522 523] [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "feat = data.x.numpy()\n",
    "print(\"Features shape:\", feat.shape)\n",
    "\n",
    "# NaN counts\n",
    "nan_counts = np.isnan(feat).sum(axis=0)\n",
    "print(\"Num features with NaNs:\", np.count_nonzero(nan_counts))\n",
    "print(\"Top 5 features by NaN count:\", \n",
    "      np.argsort(-nan_counts)[:5], nan_counts[np.argsort(-nan_counts)[:5]])\n",
    "\n",
    "# If any NaNs, replace with column median\n",
    "if np.any(nan_counts):\n",
    "    medians = np.nanmedian(feat, axis=0)\n",
    "    inds = np.where(np.isnan(feat))\n",
    "    feat[inds] = np.take(medians, inds[1])\n",
    "    data.x = torch.tensor(feat, dtype=torch.float)\n",
    "    print(\"Replaced NaNs with medians.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08906546-b2e1-41b3-9e5f-e6a1a35f3854",
   "metadata": {},
   "source": [
    "**Shape:** (10199, 788)\n",
    "We have 10 199 nodes (users) and 788 features per node. That’s a fairly high‐dimensional feature space—plenty of information for later classification, but we may eventually consider dimensionality‐reduction or feature‐selection to speed up modeling.\n",
    "\n",
    "**No NaNs anywhere**\n",
    "Since 0 features contain missing values, we don’t need to impute or drop any features. All of our node attributes are “clean,” which simplifies preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318a453",
   "metadata": {},
   "source": [
    "## 4.2 Label Distribution\n",
    "- Bot vs non-bot counts  \n",
    "- Stance label distribution  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084eb4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot label counts: [7451 2748]\n",
      "Stance label counts: [3776 3637 2786]\n"
     ]
    }
   ],
   "source": [
    "y_bot = data.y_bot.numpy()\n",
    "y_stance = data.y_stance.numpy()\n",
    "print(\"Bot label counts:\", np.bincount(y_bot))\n",
    "print(\"Stance label counts:\", np.bincount(y_stance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62627b1-b831-4f25-903f-958af3994392",
   "metadata": {},
   "source": [
    "**Bot labels: [7 451 non-bots, 2 748 bots]**\n",
    "About 27 % of the accounts are labeled as bots. This class imbalance is moderate—most classifiers can handle a 3:1 ratio, but we should still monitor precision/recall (or use class-weighted losses) to avoid biasing toward the majority class.\n",
    "\n",
    "**Stance labels: [3 776, 3 637, 2 786]**\n",
    "The three stance categories are roughly balanced (about 37 %, 36 %, and 27 %). No single class dominates unduly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae71e4",
   "metadata": {},
   "source": [
    "## 4.3 Edge Inspection & Cleaning\n",
    "- Total edges (directed?)  \n",
    "- Self‐loops  \n",
    "- Duplicate edges  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c62111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw edge count: 1700108\n",
      "After self-loop removal: 1494289\n",
      "After dedupe (coalesce): 1132578\n"
     ]
    }
   ],
   "source": [
    "# Convert to undirected for counting duplicates if needed\n",
    "edge_index = data.edge_index\n",
    "print(\"Raw edge count:\", edge_index.shape[1])\n",
    "\n",
    "# 1) Remove self-loops\n",
    "edge_index_clean, _ = remove_self_loops(edge_index)\n",
    "print(\"After self-loop removal:\", edge_index_clean.shape[1])\n",
    "\n",
    "# 2) Deduplicate & sort edges (coalesce)\n",
    "edge_index_clean, edge_attr = coalesce(\n",
    "    edge_index_clean, \n",
    "    torch.ones(edge_index_clean.shape[1]), \n",
    "    num_nodes=data.num_nodes\n",
    ")\n",
    "print(\"After dedupe (coalesce):\", edge_index_clean.shape[1])\n",
    "\n",
    "# Update data\n",
    "data.edge_index = edge_index_clean\n",
    "data.edge_weight = edge_attr  # if you want weights=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15cbe01-f46a-4ab7-80c7-5030b0ae2e17",
   "metadata": {},
   "source": [
    "**Raw edges: 1 700 108**\n",
    "Our original graph had 1.7 million directed edges.\n",
    "\n",
    "**After self-loop removal: 1 494 289**\n",
    "We dropped 205 819 self-loops (≈12 % of all edges). Bots often auto-reply to themselves, so removing these prevents overestimating their influence.\n",
    "\n",
    "**After dedupe (coalesce): 1 132 578**\n",
    "Consolidating duplicate edges reduced the edge count by another 361 711 edges. This “coalescing” merges multiple interactions into a single weighted edge—key for accurate network metrics and faster algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5086e",
   "metadata": {},
   "source": [
    "## 4.4 Connectivity Check\n",
    "- Fraction of nodes in the largest connected component  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a33fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest component: 10145 / 10199 nodes (99.47%)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "comp_sizes = [len(c) for c in nx.connected_components(G)]\n",
    "largest = max(comp_sizes)\n",
    "print(f\"Largest component: {largest} / {data.num_nodes} nodes ({largest/data.num_nodes:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5854b01-2cae-4d7f-af12-108b1d6d5a3c",
   "metadata": {},
   "source": [
    "**Largest component: 10 145 / 10 199 nodes (99.47 %)**\n",
    "Virtually the entire graph is in one big connected component. Only 54 nodes live in tiny isolated fragments. This means almost all users (and bots) are reachable via some path. Great for community detection, since we won’t have to handle many “dead ends.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee38cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: data/processed/cleaned_data.pt\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned PyG Data for analysis phase\n",
    "cleaned_path = os.path.join(cfg['mgtab_root'], 'processed', 'cleaned_data.pt')\n",
    "os.makedirs(os.path.dirname(cleaned_path), exist_ok=True)\n",
    "torch.save(data, cleaned_path)\n",
    "print(\"Cleaned data saved to:\", cleaned_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1cf43f-7235-461a-9f52-2d03674cf92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
